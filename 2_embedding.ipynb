{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Comment les LLM repr√©sentent le monde ?\n",
    "## Exploration des embeddings et des biais g√©opolitiques\n",
    "\n",
    "### Objectifs du TP\n",
    "- Comprendre le concept d'embedding et de similarit√© s√©mantique\n",
    "- Explorer comment les mod√®les de langage repr√©sentent les concepts g√©opolitiques\n",
    "- Analyser les biais potentiels dans ces repr√©sentations\n",
    "- Visualiser les relations s√©mantiques captur√©es par les embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installation et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des librairies n√©cessaires\n",
    "!pip install sentence-transformers numpy pandas matplotlib seaborn scikit-learn plotly -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour un affichage optimal\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction aux embeddings\n",
    "\n",
    "### Qu'est-ce qu'un embedding ?\n",
    "\n",
    "Un **embedding** est une repr√©sentation vectorielle dense d'un mot, d'une phrase ou d'un document. Ces vecteurs capturent les relations s√©mantiques entre les concepts.\n",
    "\n",
    "### Pourquoi c'est important ?\n",
    "- Les embeddings permettent de calculer des **similarit√©s** entre concepts\n",
    "- Ils r√©v√®lent comment le mod√®le \"comprend\" les relations entre les mots\n",
    "- **MAIS** : ils refl√®tent aussi les biais pr√©sents dans les donn√©es d'entra√Ænement !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement du mod√®le\n",
    "\n",
    "Nous utilisons un mod√®le multilingue pour pouvoir travailler avec diff√©rentes langues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du mod√®le sentence-transformers multilingue\n",
    "# Ce mod√®le est entra√Æn√© sur des donn√©es multilingues et peut encoder des phrases dans plus de 50 langues\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "print(f\"Mod√®le charg√© : {model_name}\")\n",
    "print(f\"Dimension des embeddings : {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fonctions utilitaires\n",
    "\n",
    "D√©finissons les fonctions principales pour notre exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts: List[str], model: SentenceTransformer) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    G√©n√®re les embeddings pour une liste de textes.\n",
    "    \n",
    "    Args:\n",
    "        texts: Liste de textes √† encoder\n",
    "        model: Mod√®le SentenceTransformer\n",
    "    \n",
    "    Returns:\n",
    "        Dictionnaire {texte: embedding}\n",
    "    \"\"\"\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "    return dict(zip(texts, embeddings))\n",
    "\n",
    "\n",
    "def plot_similarity_matrix(embeddings_dict: Dict[str, np.ndarray], title: str = \"Matrice de similarit√©\"):\n",
    "    \"\"\"\n",
    "    Affiche une matrice de similarit√© sous forme de heatmap.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_dict: Dictionnaire {texte: embedding}\n",
    "        title: Titre du graphique\n",
    "    \"\"\"\n",
    "    labels = list(embeddings_dict.keys())\n",
    "    embeddings = np.array(list(embeddings_dict.values()))\n",
    "    \n",
    "    # Calcul de la matrice de similarit√© cosinus\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    # Cr√©ation de la heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(similarity_matrix, \n",
    "                xticklabels=labels, \n",
    "                yticklabels=labels, \n",
    "                annot=True, \n",
    "                fmt='.2f',\n",
    "                cmap='RdBu_r',\n",
    "                vmin=-1, vmax=1,\n",
    "                square=True)\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def plot_pca_2d(embeddings_dict: Dict[str, np.ndarray], title: str = \"Projection PCA 2D\", \n",
    "                categories: Dict[str, str] = None):\n",
    "    \"\"\"\n",
    "    Projette les embeddings en 2D avec PCA et les visualise.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_dict: Dictionnaire {texte: embedding}\n",
    "        title: Titre du graphique\n",
    "        categories: Dictionnaire optionnel {texte: cat√©gorie} pour colorer les points\n",
    "    \"\"\"\n",
    "    labels = list(embeddings_dict.keys())\n",
    "    embeddings = np.array(list(embeddings_dict.values()))\n",
    "    \n",
    "    # PCA en 2D\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Cr√©ation du DataFrame pour plotly\n",
    "    df = pd.DataFrame({\n",
    "        'x': embeddings_2d[:, 0],\n",
    "        'y': embeddings_2d[:, 1],\n",
    "        'label': labels\n",
    "    })\n",
    "    \n",
    "    if categories:\n",
    "        df['category'] = [categories.get(label, 'Autre') for label in labels]\n",
    "        color_col = 'category'\n",
    "    else:\n",
    "        color_col = None\n",
    "    \n",
    "    # Visualisation interactive avec plotly\n",
    "    fig = px.scatter(df, x='x', y='y', text='label', color=color_col,\n",
    "                     title=title, \n",
    "                     labels={'x': f'PC1 ({pca.explained_variance_ratio_[0]:.1%})', \n",
    "                             'y': f'PC2 ({pca.explained_variance_ratio_[1]:.1%})'})\n",
    "    \n",
    "    fig.update_traces(textposition='top center', \n",
    "                      marker=dict(size=10))\n",
    "    \n",
    "    fig.update_layout(width=800, height=600)\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"Variance expliqu√©e : PC1={pca.explained_variance_ratio_[0]:.1%}, PC2={pca.explained_variance_ratio_[1]:.1%}\")\n",
    "    print(f\"Variance totale expliqu√©e : {sum(pca.explained_variance_ratio_):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Premier exemple : Concepts simples en fran√ßais\n",
    "\n",
    "Commen√ßons par explorer comment le mod√®le repr√©sente des concepts simples de la langue fran√ßaise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple 1 : Mots simples\n",
    "mots_simples = [\n",
    "    \"chat\", \"chien\", \"oiseau\",  # Animaux\n",
    "    \"voiture\", \"avion\", \"train\",  # Transports\n",
    "    \"pomme\", \"orange\", \"banane\",  # Fruits\n",
    "    \"Paris\", \"Londres\", \"Berlin\"  # Villes\n",
    "]\n",
    "\n",
    "# G√©n√©ration des embeddings\n",
    "embeddings_simples = generate_embeddings(mots_simples, model)\n",
    "\n",
    "# Visualisation\n",
    "print(\"=== Matrice de similarit√© ===\\n\")\n",
    "similarity_matrix = plot_similarity_matrix(embeddings_simples, \"Similarit√© entre concepts simples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des cat√©gories pour la visualisation\n",
    "categories_simples = {\n",
    "    \"chat\": \"Animaux\", \"chien\": \"Animaux\", \"oiseau\": \"Animaux\",\n",
    "    \"voiture\": \"Transports\", \"avion\": \"Transports\", \"train\": \"Transports\",\n",
    "    \"pomme\": \"Fruits\", \"orange\": \"Fruits\", \"banane\": \"Fruits\",\n",
    "    \"Paris\": \"Villes\", \"Londres\": \"Villes\", \"Berlin\": \"Villes\"\n",
    "}\n",
    "\n",
    "# Visualisation PCA\n",
    "print(\"\\n=== Projection PCA 2D ===\\n\")\n",
    "plot_pca_2d(embeddings_simples, \"Projection PCA - Concepts simples\", categories_simples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Question 1\n",
    "**Observez la matrice de similarit√© et la projection PCA. Que remarquez-vous ?**\n",
    "- Les mots de la m√™me cat√©gorie sont-ils proches ?\n",
    "- Y a-t-il des similarit√©s surprenantes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploration g√©opolitique\n",
    "\n",
    "Passons maintenant √† l'exploration de concepts g√©opolitiques plus complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Notions g√©opolitiques fondamentales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concepts g√©opolitiques\n",
    "concepts_geopolitiques = [\n",
    "    \"d√©mocratie\",\n",
    "    \"dictature\",\n",
    "    \"libert√©\",\n",
    "    \"oppression\",\n",
    "    \"d√©veloppement\",\n",
    "    \"pauvret√©\",\n",
    "    \"paix\",\n",
    "    \"guerre\",\n",
    "    \"occident\",\n",
    "    \"orient\",\n",
    "    \"nord global\",\n",
    "    \"sud global\"\n",
    "]\n",
    "\n",
    "embeddings_concepts = generate_embeddings(concepts_geopolitiques, model)\n",
    "plot_similarity_matrix(embeddings_concepts, \"Similarit√© entre concepts g√©opolitiques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat√©gorisation pour la visualisation\n",
    "categories_concepts = {\n",
    "    \"d√©mocratie\": \"Syst√®me politique\",\n",
    "    \"dictature\": \"Syst√®me politique\",\n",
    "    \"libert√©\": \"Valeurs\",\n",
    "    \"oppression\": \"Valeurs\",\n",
    "    \"d√©veloppement\": \"√âconomie\",\n",
    "    \"pauvret√©\": \"√âconomie\",\n",
    "    \"paix\": \"√âtat\",\n",
    "    \"guerre\": \"√âtat\",\n",
    "    \"occident\": \"G√©ographie\",\n",
    "    \"orient\": \"G√©ographie\",\n",
    "    \"nord global\": \"G√©ographie\",\n",
    "    \"sud global\": \"G√©ographie\"\n",
    "}\n",
    "\n",
    "plot_pca_2d(embeddings_concepts, \"Projection PCA - Concepts g√©opolitiques\", categories_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Question 2\n",
    "**Analysez les associations entre concepts :**\n",
    "- Quels concepts sont les plus proches de \"d√©mocratie\" ?\n",
    "- Comment sont positionn√©s \"occident\" et \"orient\" par rapport aux autres concepts ?\n",
    "- Ces associations vous semblent-elles neutres ou biais√©es ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Repr√©sentation des pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste de pays diversifi√©s\n",
    "pays = [\n",
    "    # Europe\n",
    "    \"France\", \"Allemagne\", \"Royaume-Uni\", \"Italie\", \"Espagne\", \"Pologne\",\n",
    "    # Am√©rique\n",
    "    \"√âtats-Unis\", \"Canada\", \"Br√©sil\", \"Argentine\", \"Mexique\",\n",
    "    # Asie\n",
    "    \"Chine\", \"Japon\", \"Inde\", \"Cor√©e du Sud\", \"Indon√©sie\",\n",
    "    # Afrique\n",
    "    \"Nigeria\", \"Afrique du Sud\", \"√âgypte\", \"Kenya\", \"Maroc\",\n",
    "    # Moyen-Orient\n",
    "    \"Arabie Saoudite\", \"Iran\", \"Isra√´l\", \"Turquie\",\n",
    "    # Oc√©anie\n",
    "    \"Australie\", \"Nouvelle-Z√©lande\"\n",
    "]\n",
    "\n",
    "embeddings_pays = generate_embeddings(pays, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_matrix(embeddings_pays, \"Matrice de similarit√© entre pays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des r√©gions pour la visualisation\n",
    "regions = {\n",
    "    \"France\": \"Europe\", \"Allemagne\": \"Europe\", \"Royaume-Uni\": \"Europe\", \n",
    "    \"Italie\": \"Europe\", \"Espagne\": \"Europe\", \"Pologne\": \"Europe\",\n",
    "    \"√âtats-Unis\": \"Am√©rique\", \"Canada\": \"Am√©rique\", \"Br√©sil\": \"Am√©rique\", \n",
    "    \"Argentine\": \"Am√©rique\", \"Mexique\": \"Am√©rique\",\n",
    "    \"Chine\": \"Asie\", \"Japon\": \"Asie\", \"Inde\": \"Asie\", \n",
    "    \"Cor√©e du Sud\": \"Asie\", \"Indon√©sie\": \"Asie\",\n",
    "    \"Nigeria\": \"Afrique\", \"Afrique du Sud\": \"Afrique\", \"√âgypte\": \"Afrique\", \n",
    "    \"Kenya\": \"Afrique\", \"Maroc\": \"Afrique\",\n",
    "    \"Arabie Saoudite\": \"Moyen-Orient\", \"Iran\": \"Moyen-Orient\", \n",
    "    \"Isra√´l\": \"Moyen-Orient\", \"Turquie\": \"Moyen-Orient\",\n",
    "    \"Australie\": \"Oc√©anie\", \"Nouvelle-Z√©lande\": \"Oc√©anie\"\n",
    "}\n",
    "\n",
    "plot_pca_2d(embeddings_pays, \"Projection PCA - Pays du monde\", regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Question 3\n",
    "**Explorez les regroupements de pays :**\n",
    "- Les pays sont-ils regroup√©s par r√©gion g√©ographique ?\n",
    "- Ou par d'autres crit√®res (√©conomiques, culturels, politiques) ?\n",
    "- Identifiez des pays \"proches\" de mani√®re surprenante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Pays dans diff√©rents contextes g√©opolitiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ons des descriptions contextualis√©es\n",
    "contextes_pays = [\n",
    "    # Contexte √©conomique\n",
    "    \"France pays d√©velopp√©\",\n",
    "    \"France √©conomie avanc√©e\",\n",
    "    \"Nigeria pays en d√©veloppement\",\n",
    "    \"Nigeria √©conomie √©mergente\",\n",
    "    \n",
    "    # Contexte politique\n",
    "    \"√âtats-Unis d√©mocratie\",\n",
    "    \"√âtats-Unis superpuissance\",\n",
    "    \"Chine r√©gime autoritaire\",\n",
    "    \"Chine puissance montante\",\n",
    "    \n",
    "    # Contexte culturel\n",
    "    \"Japon tradition moderne\",\n",
    "    \"Japon technologie avanc√©e\",\n",
    "    \"Inde diversit√© culturelle\",\n",
    "    \"Inde d√©mocratie peupl√©e\",\n",
    "    \n",
    "    # Contexte conflictuel\n",
    "    \"Isra√´l conflit r√©gional\",\n",
    "    \"Palestine territoire occup√©\",\n",
    "    \"Ukraine guerre 2022\",\n",
    "    \"Russie agression militaire\"\n",
    "]\n",
    "\n",
    "embeddings_contextes = generate_embeddings(contextes_pays, model)\n",
    "plot_similarity_matrix(embeddings_contextes, \"Similarit√© entre pays en contexte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cat√©gorisons par type de contexte\n",
    "categories_contextes = {\n",
    "    \"France pays d√©velopp√©\": \"√âconomique\",\n",
    "    \"France √©conomie avanc√©e\": \"√âconomique\",\n",
    "    \"Nigeria pays en d√©veloppement\": \"√âconomique\",\n",
    "    \"Nigeria √©conomie √©mergente\": \"√âconomique\",\n",
    "    \"√âtats-Unis d√©mocratie\": \"Politique\",\n",
    "    \"√âtats-Unis superpuissance\": \"Politique\",\n",
    "    \"Chine r√©gime autoritaire\": \"Politique\",\n",
    "    \"Chine puissance montante\": \"Politique\",\n",
    "    \"Japon tradition moderne\": \"Culturel\",\n",
    "    \"Japon technologie avanc√©e\": \"Culturel\",\n",
    "    \"Inde diversit√© culturelle\": \"Culturel\",\n",
    "    \"Inde d√©mocratie peupl√©e\": \"Culturel\",\n",
    "    \"Isra√´l conflit r√©gional\": \"Conflictuel\",\n",
    "    \"Palestine territoire occup√©\": \"Conflictuel\",\n",
    "    \"Ukraine guerre 2022\": \"Conflictuel\",\n",
    "    \"Russie agression militaire\": \"Conflictuel\"\n",
    "}\n",
    "\n",
    "plot_pca_2d(embeddings_contextes, \"Projection PCA - Pays en contexte\", categories_contextes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Question 4\n",
    "**Analysez l'impact du contexte :**\n",
    "- Comment le contexte change-t-il la position d'un pays dans l'espace des embeddings ?\n",
    "- Les descriptions positives/n√©gatives influencent-elles les similarit√©s ?\n",
    "- Quels biais potentiels identifiez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploration libre et r√©flexion\n",
    "\n",
    "### 6.1 Testez vos propres hypoth√®ses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zone d'exp√©rimentation libre\n",
    "# Modifiez cette liste pour tester vos propres concepts !\n",
    "\n",
    "mes_concepts = [\n",
    "    # Exemple : st√©r√©otypes de genre\n",
    "    \"homme fort\",\n",
    "    \"femme forte\",\n",
    "    \"homme sensible\",\n",
    "    \"femme sensible\",\n",
    "    \n",
    "    # Exemple : professions\n",
    "    \"ing√©nieur\",\n",
    "    \"infirmi√®re\",\n",
    "    \"PDG\",\n",
    "    \"secr√©taire\",\n",
    "    \n",
    "    # Ajoutez vos propres concepts ici !\n",
    "    \n",
    "]\n",
    "\n",
    "# G√©n√©ration et visualisation\n",
    "embeddings_libres = generate_embeddings(mes_concepts, model)\n",
    "plot_similarity_matrix(embeddings_libres, \"Exploration libre - Mes concepts\")\n",
    "plot_pca_2d(embeddings_libres, \"Projection PCA - Mes concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Analyse comparative multilingue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testons la repr√©sentation d'un m√™me concept dans diff√©rentes langues\n",
    "concepts_multilingues = [\n",
    "    # Libert√©\n",
    "    \"libert√©\",        # Fran√ßais\n",
    "    \"freedom\",        # Anglais\n",
    "    \"libertad\",       # Espagnol\n",
    "    \"Freiheit\",       # Allemand\n",
    "    \"Ëá™Áî±\",           # Chinois\n",
    "    \"ÿ≠ÿ±Ÿäÿ©\",          # Arabe\n",
    "    \n",
    "    # Paix\n",
    "    \"paix\",          # Fran√ßais\n",
    "    \"peace\",         # Anglais\n",
    "    \"paz\",           # Espagnol\n",
    "    \"Frieden\",       # Allemand\n",
    "    \"ÂíåÂπ≥\",          # Chinois\n",
    "    \"ÿ≥ŸÑÿßŸÖ\",          # Arabe\n",
    "]\n",
    "\n",
    "embeddings_multilingue = generate_embeddings(concepts_multilingues, model)\n",
    "plot_similarity_matrix(embeddings_multilingue, \"Similarit√© multilingue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Question 5\n",
    "**R√©flexion finale :**\n",
    "- Les m√™mes concepts sont-ils repr√©sent√©s de la m√™me fa√ßon dans diff√©rentes langues ?\n",
    "- Quelles implications cela a-t-il pour l'utilisation de mod√®les multilingues ?\n",
    "- Comment pourrait-on d√©tecter et corriger les biais identifi√©s ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pour aller plus loin\n",
    "\n",
    "### 7.1 Comparaison avec d'autres mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste d'autres mod√®les √† essayer\n",
    "autres_modeles = [\n",
    "    'sentence-transformers/all-MiniLM-L6-v2',  # Anglais uniquement\n",
    "    'sentence-transformers/distiluse-base-multilingual-cased-v2',  # Multilingue\n",
    "    'sentence-transformers/LaBSE',  # Large-scale multilingual\n",
    "]\n",
    "\n",
    "print(\"Autres mod√®les que vous pouvez tester :\")\n",
    "for modele in autres_modeles:\n",
    "    print(f\"- {modele}\")\n",
    "\n",
    "# D√©commentez pour tester un autre mod√®le\n",
    "# nouveau_model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "# nouveaux_embeddings = generate_embeddings(pays[:10], nouveau_model)\n",
    "# plot_pca_2d(nouveaux_embeddings, \"Projection avec LaBSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions et discussions\n",
    "\n",
    "### Points cl√©s √† retenir :\n",
    "\n",
    "1. **Les embeddings capturent des relations s√©mantiques complexes**\n",
    "   - Similarit√©s conceptuelles\n",
    "   - Relations g√©ographiques et culturelles\n",
    "   - Associations contextuelles\n",
    "\n",
    "2. **Les biais sont omnipr√©sents**\n",
    "   - Reflet des donn√©es d'entra√Ænement\n",
    "   - Associations culturelles et historiques\n",
    "   - St√©r√©otypes sociaux\n",
    "\n",
    "3. **Implications pratiques**\n",
    "   - N√©cessit√© de tester et auditer les mod√®les\n",
    "   - Importance du contexte d'utilisation\n",
    "   - Besoin de diversit√© dans les donn√©es\n",
    "\n",
    "### Questions pour la discussion :\n",
    "\n",
    "- Comment peut-on utiliser ces mod√®les de mani√®re √©thique ?\n",
    "- Quelles pr√©cautions prendre dans des applications sensibles ?\n",
    "- Comment am√©liorer la repr√©sentation √©quitable des diff√©rentes cultures ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
